{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">Assignment: Implement a CNN for Image Classification on CIFAR10 dataset</font>\n",
    "\n",
    "We have seen how to implement a CNN (LeNet5 and LeNet with the batch norm) in the last section. We used MNIST and Fashion MNIST dataset which are grayscale or single channel datasets. In this assignment, you will implement a CNN Model ( similar to LeNet ) for classifying objects in the `CIFAR10` dataset. \n",
    "\n",
    "The CIFAR10 dataset has the following properties\n",
    "1. It has `10` classes.  \n",
    "1. It has colored images, so it has `3-channels`. \n",
    "1. The image shape is `32 x 32`.\n",
    "\n",
    "Samples of CIFAR10- dataset ([source](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=cifar)):\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/01/c3_w3_cirar10.png\" width=700>\n",
    "\n",
    "\n",
    "# <font color='blue'>Marking Scheme</font>\n",
    "\n",
    "### <font style=\"color:green\">Maximum Points: 30\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Problem</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Implement the CNN Model</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Find Mean and Std of Training Data</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Model Training & Accuracy</h3></td> <td><h3>15</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "\n",
    "# <font color='blue'>Problem Description</font>\n",
    "\n",
    "### <font color='blue'>1. Implement the CNN Model</font>\n",
    "Since the task is to classify objects in a dataset of color images, you need to implement a CNN with 10 output classes. **Also, your model must use `Conv2d`, `BatchNorm2d`, and `ReLU`.** \n",
    "\n",
    "**You need to define the model architecture in the function: `MyModel` ( Step 1 )**\n",
    "\n",
    "Hint: For color images you need to use an input shape that is different than the ones we have been using till now, so that it accepts 3 channel inputs.\n",
    "\n",
    "### <font color='blue'>2. Find Mean and Std of Training Data</font>\n",
    "\n",
    "It is a good practice to normalize the training data. To normalize the data, we need to compute mean and std. As the dataset has colored images, it has `3-channel` (RGB or BGR). We have to find mean and std per channel using training data. \n",
    "\n",
    "**You need to compute the mean and std for the dataset in the function: `get_mean_std_train_data` ( Step 3 )**\n",
    "\n",
    "### <font color='blue'>3. Model Training and Accuracy</font>\n",
    "\n",
    "Once you have defined the model, you can train it. To get better accuracy, you need to play around the training configuration **( Step 5 )** and even the model architecture. You can check the accuracy by running the training loop in `Step 11`.\n",
    "\n",
    "Here are a few hints on how you can improve the accuracy:\n",
    "- Train for longer duration\n",
    "- Try with different learning rate\n",
    "- Try to add more convolutional layers to the architecture\n",
    "- Try to add more nodes in the layers.\n",
    "\n",
    "You need to achieve **75% accuracy** ( See Step11 ) in order to get full marks for this part. \n",
    "\n",
    "**You do not need to implement anything for this, just changing the parameters as mentioned above and running the Notebook will give you the accuracy. ( Step 5 and Step 11 )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # one of the best graphics library for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">1. CNN Model Architecture [10 Points]</font>\n",
    "\n",
    "You have to write the model code here. You can take reference from LeNet code.\n",
    "\n",
    "If you do not get higher accuracy, here are a few hints:\n",
    "- Try to add more convolutional layers to the architecture\n",
    "- Try to add more nodes in the layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ###\n",
    "        ### YOUR CODE HERE\n",
    "        ###\n",
    "\n",
    "        self._body = nn.Sequential(\n",
    "            # input size = (32, 32), 32 filters, output size = (32, 32)\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            # output (16, 16)\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # input (16, 16), output (16, 16)\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # output (8, 8)\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "\n",
    "            # input (8, 8), output (8, 8)\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            # output (4, 4)\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "        )\n",
    "\n",
    "        self._head = nn.Sequential(\n",
    "            # First fully connected layer\n",
    "            # in_features = total number of weight in last conv layer = 128 * 4 * 4\n",
    "            nn.Linear(in_features=128 * 4 * 4, out_features=512), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            # second fully connected layer\n",
    "            nn.Linear(in_features=512, out_features=10), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ###\n",
    "        ### YOUR CODE HERE\n",
    "        ###\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weight_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">2. Display the Network</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MyModel(\n  (_body): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU(inplace=True)\n    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Dropout2d(p=0.25, inplace=False)\n    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (12): ReLU(inplace=True)\n    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (15): Dropout2d(p=0.25, inplace=False)\n    (16): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): ReLU(inplace=True)\n    (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (23): Dropout2d(p=0.25, inplace=False)\n  )\n  (_head): Sequential(\n    (0): Linear(in_features=2048, out_features=512, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.25, inplace=False)\n    (3): Linear(in_features=512, out_features=10, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.25, inplace=False)\n  )\n)\n"
    }
   ],
   "source": [
    "my_model = MyModel()\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">3. Find Mean and STD of CIFAR10 Data [5 Points]</font>\n",
    "\n",
    "Function **`get_mean_std_train_data`** should `return` `mean` and `std` of training data. You can refer to the code used in the previous section for finding the mean and std of the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_train_data(data_root):\n",
    "    \n",
    "    train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_set = datasets.CIFAR10(root=data_root, train=True, download=False, transform=train_transform)\n",
    "    \n",
    "    # return mean (numpy.ndarray) and std (numpy.ndarray)\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    \n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    mean = train_set.data.mean((0,1,2))/255\n",
    "    std = train_set.data.std((0,1,2))/255\n",
    "\n",
    "    return mean, std\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root, num_workers=1):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        mean, std = get_mean_std_train_data(data_root)\n",
    "        assert len(mean) == len(std) == 3\n",
    "    except:\n",
    "        mean = np.array([0.5, 0.5, 0.5])\n",
    "        std = np.array([0.5, 0.5, 0.5])\n",
    "        \n",
    "    \n",
    "    train_test_transforms = transforms.Compose([\n",
    "        # this re-scale image tensor values between 0-1. image_tensor /= 255\n",
    "        transforms.ToTensor(),\n",
    "        # subtract mean and divide by variance.\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    # train dataloader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root=data_root, train=True, download=False, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    # test dataloader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root=data_root, train=False, download=False, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">4. System Configuration</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">5. Training Configuration [15 Points]</font>\n",
    "All training parameters are defined here. So, \n",
    "This is where you can improve your accuracy, apart from improving the architecture. \n",
    "\n",
    "Here are a few hints on how you can improve the accuracy:\n",
    "- Train for longer duration\n",
    "- Try with different learning rate\n",
    "\n",
    "**You need to achieve 75% accuracy in order to get full marks for this part.**\n",
    "\n",
    "**You will see the effect of these changes when you run Step 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 32  # amount of data to pass through the network at each forward-backward iteration\n",
    "    epochs_count: int = 20  # number of times the whole dataset will be passed through the network\n",
    "    learning_rate: float = 0.01  # determines the speed of network's weights update\n",
    "        \n",
    "    log_interval: int = 100  # how many batches to wait between logging training status\n",
    "    test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
    "    data_root: str = \"./data/images\"  # folder to save data\n",
    "    num_workers: int = 10  # number of concurrent processes using to prepare data\n",
    "    device: str = 'cuda'  # device to use for training.\n",
    "    # update changed parameters in blow coding block.\n",
    "    # Please do not change \"data_root\" \n",
    "    \n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">6. System Setup</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">7. Training</font>\n",
    "We are familiar with the training pipeline used in PyTorch. The following steps are performed in the code below:\n",
    "\n",
    "1. Send the data to the required device ( CPU/GPU )\n",
    "1. Make a forward pass using the forward method.\n",
    "1. Find the loss using the Cross_Entropy function.\n",
    "1. Find the gradients using the backward function.\n",
    "1. Update the weights using the optimizer.\n",
    "1. Find the accuracy of the model\n",
    "\n",
    "Repeat the above for the specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> None:\n",
    "    from IPython.core.debugger import set_trace\n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        set_trace()\n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "\n",
    "        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:              \n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    epoch_idx, batch_idx * len(data), len(train_loader.dataset), loss.item(), acc\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">8. Validation</font>\n",
    "\n",
    "After every few epochs **`validation`** will be called with the `trained model` and `test_loader` to get validation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    for data, target in test_loader:\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        \n",
    "        target = target.to(train_config.device)\n",
    "        \n",
    "        output = model(data)\n",
    "        # add loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1] \n",
    "        \n",
    "        # add correct prediction count\n",
    "        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "    # average over number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)  \n",
    "    \n",
    "    # average over number of dataset\n",
    "    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">9. Saving the Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='models', model_file_name='cifar10_cnn_model.pt'):\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">10. Main</font>\n",
    "\n",
    "In this section of code, we use the configuration parameters defined above and start the training. Here are the important actions being taken in the code below:\n",
    "\n",
    "1. Set up system parameters like CPU/GPU, number of threads etc\n",
    "1. Load the data using dataloaders\n",
    "1. Create an instance of the LeNet model\n",
    "1. Specify optimizer to use.\n",
    "1. Set up variables to track loss and accuracy and start training.\n",
    "1. If loss decreases, saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(system_configuration=SystemConfiguration(), training_configuration=TrainingConfiguration()):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lowers batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        num_workers_to_set = 2\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=training_configuration.batch_size,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "\n",
    "    # initiate model\n",
    "    model = MyModel()\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=training_configuration.learning_rate\n",
    "    )\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                print('Loss decreases, saving the model.\\n')\n",
    "                save_model(model, device)\n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Step 11: Start Training</font>\n",
    "This is where you start the training. You may see that the training does not converge or does not give a good accuracy. You need to change \n",
    "- In Step 1: the network architecture and add a few more layers or more nodes to the already existing layers\n",
    "- In Step 5: training parameters such as learning rate or batch_size or epochs so that the network converges or run the network for longer so that it gets more time to fit the data\n",
    "\n",
    "**You need to make sure that the accuracy at the end is at least 75%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\n> \u001b[1;32m<ipython-input-74-da9a7f42818b>\u001b[0m(36)\u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[1;32m     34 \u001b[1;33m        \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35 \u001b[1;33m        \u001b[1;31m# Update parameters using gardients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m---> 36 \u001b[1;33m        \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38 \u001b[1;33m        \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\n> \u001b[1;32m<ipython-input-74-da9a7f42818b>\u001b[0m(38)\u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[1;32m     36 \u001b[1;33m        \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m---> 38 \u001b[1;33m        \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40 \u001b[1;33m        \u001b[1;31m# Score to probability using softmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\n> \u001b[1;32m<ipython-input-74-da9a7f42818b>\u001b[0m(41)\u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[1;32m     39 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40 \u001b[1;33m        \u001b[1;31m# Score to probability using softmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m---> 41 \u001b[1;33m        \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43 \u001b[1;33m        \u001b[1;31m# get the index of the max probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\ntorch.Size([32, 10])\n> \u001b[1;32m<ipython-input-74-da9a7f42818b>\u001b[0m(44)\u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[1;32m     42 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43 \u001b[1;33m        \u001b[1;31m# get the index of the max probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m---> 44 \u001b[1;33m        \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46 \u001b[1;33m        \u001b[1;31m# correct prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\ntorch.Size([32, 10])\ntorch.Size([32, 10])\ntorch.Size([32, 10])\ntorch.Size([32, 10])\ntorch.Size([32, 10])\ntensor([[0.0737, 0.0737, 0.0737, 0.0737, 0.0737, 0.2756, 0.0737, 0.1192, 0.0737,\n         0.0897],\n        [0.0783, 0.0855, 0.0783, 0.1687, 0.0783, 0.1177, 0.0783, 0.1581, 0.0783,\n         0.0783],\n        [0.0785, 0.2170, 0.0785, 0.1279, 0.0947, 0.0785, 0.0785, 0.0785, 0.0895,\n         0.0785],\n        [0.0505, 0.3164, 0.0505, 0.2293, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505,\n         0.1008],\n        [0.0645, 0.0713, 0.1990, 0.1033, 0.1393, 0.1060, 0.0645, 0.0645, 0.0645,\n         0.1233],\n        [0.0779, 0.1562, 0.0779, 0.0809, 0.0779, 0.1578, 0.1214, 0.0779, 0.0779,\n         0.0941],\n        [0.0503, 0.0503, 0.0503, 0.0503, 0.0652, 0.0503, 0.3677, 0.0503, 0.0503,\n         0.2152],\n        [0.1032, 0.0966, 0.0966, 0.1243, 0.0966, 0.0966, 0.0966, 0.0966, 0.0966,\n         0.0966],\n        [0.0831, 0.0831, 0.0831, 0.2058, 0.0831, 0.0831, 0.1294, 0.0831, 0.0831,\n         0.0831],\n        [0.0600, 0.1620, 0.0661, 0.0600, 0.0921, 0.0600, 0.1040, 0.0600, 0.0600,\n         0.2758],\n        [0.0720, 0.1075, 0.0596, 0.1170, 0.0961, 0.1472, 0.0596, 0.0596, 0.0596,\n         0.2218],\n        [0.0494, 0.1242, 0.0494, 0.1877, 0.0541, 0.0494, 0.2862, 0.0494, 0.0494,\n         0.1006],\n        [0.0829, 0.0829, 0.0829, 0.0829, 0.0829, 0.1332, 0.1696, 0.0829, 0.0829,\n         0.1168],\n        [0.0684, 0.0684, 0.0684, 0.1836, 0.0684, 0.0888, 0.1454, 0.0684, 0.0684,\n         0.1716],\n        [0.0814, 0.0814, 0.0814, 0.1261, 0.0814, 0.0814, 0.0814, 0.0814, 0.0975,\n         0.2066],\n        [0.1094, 0.0837, 0.0837, 0.2208, 0.0837, 0.0837, 0.0837, 0.0837, 0.0837,\n         0.0837],\n        [0.0885, 0.0885, 0.1232, 0.0885, 0.1402, 0.0885, 0.0885, 0.0885, 0.0989,\n         0.1068],\n        [0.0702, 0.0967, 0.0702, 0.1145, 0.0702, 0.0702, 0.1795, 0.1359, 0.1222,\n         0.0702],\n        [0.0976, 0.1138, 0.0813, 0.0813, 0.1243, 0.1551, 0.1024, 0.0813, 0.0813,\n         0.0813],\n        [0.0879, 0.0879, 0.0879, 0.1152, 0.0976, 0.1201, 0.0879, 0.0879, 0.0947,\n         0.1330],\n        [0.0641, 0.3647, 0.0641, 0.0641, 0.0641, 0.0641, 0.1001, 0.0641, 0.0862,\n         0.0641],\n        [0.0634, 0.0634, 0.0634, 0.1094, 0.1261, 0.1252, 0.0634, 0.0672, 0.0634,\n         0.2549],\n        [0.0987, 0.0798, 0.0798, 0.0798, 0.0798, 0.1362, 0.0798, 0.1077, 0.0798,\n         0.1785],\n        [0.0685, 0.0685, 0.0685, 0.0685, 0.0685, 0.1385, 0.0685, 0.0685, 0.0685,\n         0.3131],\n        [0.1161, 0.0867, 0.0867, 0.1087, 0.0867, 0.1672, 0.0867, 0.0867, 0.0877,\n         0.0867],\n        [0.0769, 0.0906, 0.0769, 0.0769, 0.0769, 0.1138, 0.1039, 0.1129, 0.1398,\n         0.1314],\n        [0.0887, 0.1889, 0.0887, 0.0887, 0.0887, 0.1016, 0.0887, 0.0887, 0.0887,\n         0.0887],\n        [0.0939, 0.0939, 0.0939, 0.1547, 0.0939, 0.0939, 0.0939, 0.0939, 0.0939,\n         0.0939],\n        [0.1183, 0.1342, 0.0845, 0.1103, 0.0837, 0.1227, 0.0909, 0.0837, 0.0837,\n         0.0881],\n        [0.0804, 0.2258, 0.0557, 0.2746, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557,\n         0.0851],\n        [0.0596, 0.1807, 0.0596, 0.0596, 0.0596, 0.1752, 0.0596, 0.1520, 0.0596,\n         0.1348],\n        [0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882,\n         0.2059]], grad_fn=<SoftmaxBackward>)\n32\n32\n32\n32\n32\n32\n32\n32\n32\n32\n32\n32\ntorch.Size([32, 10])\ntorch.Size([32, 10])\n> \u001b[1;32m<ipython-input-74-da9a7f42818b>\u001b[0m(47)\u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[1;32m     45 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46 \u001b[1;33m        \u001b[1;31m# correct prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m---> 47 \u001b[1;33m        \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindx_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49 \u001b[1;33m        \u001b[1;31m# accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\n> \u001b[1;32m<ipython-input-74-da9a7f42818b>\u001b[0m(50)\u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[1;32m     48 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49 \u001b[1;33m        \u001b[1;31m# accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m---> 50 \u001b[1;33m        \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52 \u001b[1;33m        \u001b[0mbatch_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n*** NameError: name 'prod' is not defined\n> \u001b[1;32m<ipython-input-74-da9a7f42818b>\u001b[0m(52)\u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[1;32m     50 \u001b[1;33m        \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m---> 52 \u001b[1;33m        \u001b[0mbatch_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\ntensor([[0.0737, 0.0737, 0.0737, 0.0737, 0.0737, 0.2756, 0.0737, 0.1192, 0.0737,\n         0.0897],\n        [0.0783, 0.0855, 0.0783, 0.1687, 0.0783, 0.1177, 0.0783, 0.1581, 0.0783,\n         0.0783],\n        [0.0785, 0.2170, 0.0785, 0.1279, 0.0947, 0.0785, 0.0785, 0.0785, 0.0895,\n         0.0785],\n        [0.0505, 0.3164, 0.0505, 0.2293, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505,\n         0.1008],\n        [0.0645, 0.0713, 0.1990, 0.1033, 0.1393, 0.1060, 0.0645, 0.0645, 0.0645,\n         0.1233],\n        [0.0779, 0.1562, 0.0779, 0.0809, 0.0779, 0.1578, 0.1214, 0.0779, 0.0779,\n         0.0941],\n        [0.0503, 0.0503, 0.0503, 0.0503, 0.0652, 0.0503, 0.3677, 0.0503, 0.0503,\n         0.2152],\n        [0.1032, 0.0966, 0.0966, 0.1243, 0.0966, 0.0966, 0.0966, 0.0966, 0.0966,\n         0.0966],\n        [0.0831, 0.0831, 0.0831, 0.2058, 0.0831, 0.0831, 0.1294, 0.0831, 0.0831,\n         0.0831],\n        [0.0600, 0.1620, 0.0661, 0.0600, 0.0921, 0.0600, 0.1040, 0.0600, 0.0600,\n         0.2758],\n        [0.0720, 0.1075, 0.0596, 0.1170, 0.0961, 0.1472, 0.0596, 0.0596, 0.0596,\n         0.2218],\n        [0.0494, 0.1242, 0.0494, 0.1877, 0.0541, 0.0494, 0.2862, 0.0494, 0.0494,\n         0.1006],\n        [0.0829, 0.0829, 0.0829, 0.0829, 0.0829, 0.1332, 0.1696, 0.0829, 0.0829,\n         0.1168],\n        [0.0684, 0.0684, 0.0684, 0.1836, 0.0684, 0.0888, 0.1454, 0.0684, 0.0684,\n         0.1716],\n        [0.0814, 0.0814, 0.0814, 0.1261, 0.0814, 0.0814, 0.0814, 0.0814, 0.0975,\n         0.2066],\n        [0.1094, 0.0837, 0.0837, 0.2208, 0.0837, 0.0837, 0.0837, 0.0837, 0.0837,\n         0.0837],\n        [0.0885, 0.0885, 0.1232, 0.0885, 0.1402, 0.0885, 0.0885, 0.0885, 0.0989,\n         0.1068],\n        [0.0702, 0.0967, 0.0702, 0.1145, 0.0702, 0.0702, 0.1795, 0.1359, 0.1222,\n         0.0702],\n        [0.0976, 0.1138, 0.0813, 0.0813, 0.1243, 0.1551, 0.1024, 0.0813, 0.0813,\n         0.0813],\n        [0.0879, 0.0879, 0.0879, 0.1152, 0.0976, 0.1201, 0.0879, 0.0879, 0.0947,\n         0.1330],\n        [0.0641, 0.3647, 0.0641, 0.0641, 0.0641, 0.0641, 0.1001, 0.0641, 0.0862,\n         0.0641],\n        [0.0634, 0.0634, 0.0634, 0.1094, 0.1261, 0.1252, 0.0634, 0.0672, 0.0634,\n         0.2549],\n        [0.0987, 0.0798, 0.0798, 0.0798, 0.0798, 0.1362, 0.0798, 0.1077, 0.0798,\n         0.1785],\n        [0.0685, 0.0685, 0.0685, 0.0685, 0.0685, 0.1385, 0.0685, 0.0685, 0.0685,\n         0.3131],\n        [0.1161, 0.0867, 0.0867, 0.1087, 0.0867, 0.1672, 0.0867, 0.0867, 0.0877,\n         0.0867],\n        [0.0769, 0.0906, 0.0769, 0.0769, 0.0769, 0.1138, 0.1039, 0.1129, 0.1398,\n         0.1314],\n        [0.0887, 0.1889, 0.0887, 0.0887, 0.0887, 0.1016, 0.0887, 0.0887, 0.0887,\n         0.0887],\n        [0.0939, 0.0939, 0.0939, 0.1547, 0.0939, 0.0939, 0.0939, 0.0939, 0.0939,\n         0.0939],\n        [0.1183, 0.1342, 0.0845, 0.1103, 0.0837, 0.1227, 0.0909, 0.0837, 0.0837,\n         0.0881],\n        [0.0804, 0.2258, 0.0557, 0.2746, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557,\n         0.0851],\n        [0.0596, 0.1807, 0.0596, 0.0596, 0.0596, 0.1752, 0.0596, 0.1520, 0.0596,\n         0.1348],\n        [0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882,\n         0.2059]], grad_fn=<SoftmaxBackward>)\ntensor([[0.0737, 0.0737, 0.0737, 0.0737, 0.0737, 0.2756, 0.0737, 0.1192, 0.0737,\n         0.0897],\n        [0.0783, 0.0855, 0.0783, 0.1687, 0.0783, 0.1177, 0.0783, 0.1581, 0.0783,\n         0.0783],\n        [0.0785, 0.2170, 0.0785, 0.1279, 0.0947, 0.0785, 0.0785, 0.0785, 0.0895,\n         0.0785],\n        [0.0505, 0.3164, 0.0505, 0.2293, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505,\n         0.1008],\n        [0.0645, 0.0713, 0.1990, 0.1033, 0.1393, 0.1060, 0.0645, 0.0645, 0.0645,\n         0.1233],\n        [0.0779, 0.1562, 0.0779, 0.0809, 0.0779, 0.1578, 0.1214, 0.0779, 0.0779,\n         0.0941],\n        [0.0503, 0.0503, 0.0503, 0.0503, 0.0652, 0.0503, 0.3677, 0.0503, 0.0503,\n         0.2152],\n        [0.1032, 0.0966, 0.0966, 0.1243, 0.0966, 0.0966, 0.0966, 0.0966, 0.0966,\n         0.0966],\n        [0.0831, 0.0831, 0.0831, 0.2058, 0.0831, 0.0831, 0.1294, 0.0831, 0.0831,\n         0.0831],\n        [0.0600, 0.1620, 0.0661, 0.0600, 0.0921, 0.0600, 0.1040, 0.0600, 0.0600,\n         0.2758],\n        [0.0720, 0.1075, 0.0596, 0.1170, 0.0961, 0.1472, 0.0596, 0.0596, 0.0596,\n         0.2218],\n        [0.0494, 0.1242, 0.0494, 0.1877, 0.0541, 0.0494, 0.2862, 0.0494, 0.0494,\n         0.1006],\n        [0.0829, 0.0829, 0.0829, 0.0829, 0.0829, 0.1332, 0.1696, 0.0829, 0.0829,\n         0.1168],\n        [0.0684, 0.0684, 0.0684, 0.1836, 0.0684, 0.0888, 0.1454, 0.0684, 0.0684,\n         0.1716],\n        [0.0814, 0.0814, 0.0814, 0.1261, 0.0814, 0.0814, 0.0814, 0.0814, 0.0975,\n         0.2066],\n        [0.1094, 0.0837, 0.0837, 0.2208, 0.0837, 0.0837, 0.0837, 0.0837, 0.0837,\n         0.0837],\n        [0.0885, 0.0885, 0.1232, 0.0885, 0.1402, 0.0885, 0.0885, 0.0885, 0.0989,\n         0.1068],\n        [0.0702, 0.0967, 0.0702, 0.1145, 0.0702, 0.0702, 0.1795, 0.1359, 0.1222,\n         0.0702],\n        [0.0976, 0.1138, 0.0813, 0.0813, 0.1243, 0.1551, 0.1024, 0.0813, 0.0813,\n         0.0813],\n        [0.0879, 0.0879, 0.0879, 0.1152, 0.0976, 0.1201, 0.0879, 0.0879, 0.0947,\n         0.1330],\n        [0.0641, 0.3647, 0.0641, 0.0641, 0.0641, 0.0641, 0.1001, 0.0641, 0.0862,\n         0.0641],\n        [0.0634, 0.0634, 0.0634, 0.1094, 0.1261, 0.1252, 0.0634, 0.0672, 0.0634,\n         0.2549],\n        [0.0987, 0.0798, 0.0798, 0.0798, 0.0798, 0.1362, 0.0798, 0.1077, 0.0798,\n         0.1785],\n        [0.0685, 0.0685, 0.0685, 0.0685, 0.0685, 0.1385, 0.0685, 0.0685, 0.0685,\n         0.3131],\n        [0.1161, 0.0867, 0.0867, 0.1087, 0.0867, 0.1672, 0.0867, 0.0867, 0.0877,\n         0.0867],\n        [0.0769, 0.0906, 0.0769, 0.0769, 0.0769, 0.1138, 0.1039, 0.1129, 0.1398,\n         0.1314],\n        [0.0887, 0.1889, 0.0887, 0.0887, 0.0887, 0.1016, 0.0887, 0.0887, 0.0887,\n         0.0887],\n        [0.0939, 0.0939, 0.0939, 0.1547, 0.0939, 0.0939, 0.0939, 0.0939, 0.0939,\n         0.0939],\n        [0.1183, 0.1342, 0.0845, 0.1103, 0.0837, 0.1227, 0.0909, 0.0837, 0.0837,\n         0.0881],\n        [0.0804, 0.2258, 0.0557, 0.2746, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557,\n         0.0851],\n        [0.0596, 0.1807, 0.0596, 0.0596, 0.0596, 0.1752, 0.0596, 0.1520, 0.0596,\n         0.1348],\n        [0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882,\n         0.2059]], grad_fn=<SoftmaxBackward>)\ntensor([[0.0737, 0.0737, 0.0737, 0.0737, 0.0737, 0.2756, 0.0737, 0.1192, 0.0737,\n         0.0897],\n        [0.0783, 0.0855, 0.0783, 0.1687, 0.0783, 0.1177, 0.0783, 0.1581, 0.0783,\n         0.0783],\n        [0.0785, 0.2170, 0.0785, 0.1279, 0.0947, 0.0785, 0.0785, 0.0785, 0.0895,\n         0.0785],\n        [0.0505, 0.3164, 0.0505, 0.2293, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505,\n         0.1008],\n        [0.0645, 0.0713, 0.1990, 0.1033, 0.1393, 0.1060, 0.0645, 0.0645, 0.0645,\n         0.1233],\n        [0.0779, 0.1562, 0.0779, 0.0809, 0.0779, 0.1578, 0.1214, 0.0779, 0.0779,\n         0.0941],\n        [0.0503, 0.0503, 0.0503, 0.0503, 0.0652, 0.0503, 0.3677, 0.0503, 0.0503,\n         0.2152],\n        [0.1032, 0.0966, 0.0966, 0.1243, 0.0966, 0.0966, 0.0966, 0.0966, 0.0966,\n         0.0966],\n        [0.0831, 0.0831, 0.0831, 0.2058, 0.0831, 0.0831, 0.1294, 0.0831, 0.0831,\n         0.0831],\n        [0.0600, 0.1620, 0.0661, 0.0600, 0.0921, 0.0600, 0.1040, 0.0600, 0.0600,\n         0.2758],\n        [0.0720, 0.1075, 0.0596, 0.1170, 0.0961, 0.1472, 0.0596, 0.0596, 0.0596,\n         0.2218],\n        [0.0494, 0.1242, 0.0494, 0.1877, 0.0541, 0.0494, 0.2862, 0.0494, 0.0494,\n         0.1006],\n        [0.0829, 0.0829, 0.0829, 0.0829, 0.0829, 0.1332, 0.1696, 0.0829, 0.0829,\n         0.1168],\n        [0.0684, 0.0684, 0.0684, 0.1836, 0.0684, 0.0888, 0.1454, 0.0684, 0.0684,\n         0.1716],\n        [0.0814, 0.0814, 0.0814, 0.1261, 0.0814, 0.0814, 0.0814, 0.0814, 0.0975,\n         0.2066],\n        [0.1094, 0.0837, 0.0837, 0.2208, 0.0837, 0.0837, 0.0837, 0.0837, 0.0837,\n         0.0837],\n        [0.0885, 0.0885, 0.1232, 0.0885, 0.1402, 0.0885, 0.0885, 0.0885, 0.0989,\n         0.1068],\n        [0.0702, 0.0967, 0.0702, 0.1145, 0.0702, 0.0702, 0.1795, 0.1359, 0.1222,\n         0.0702],\n        [0.0976, 0.1138, 0.0813, 0.0813, 0.1243, 0.1551, 0.1024, 0.0813, 0.0813,\n         0.0813],\n        [0.0879, 0.0879, 0.0879, 0.1152, 0.0976, 0.1201, 0.0879, 0.0879, 0.0947,\n         0.1330],\n        [0.0641, 0.3647, 0.0641, 0.0641, 0.0641, 0.0641, 0.1001, 0.0641, 0.0862,\n         0.0641],\n        [0.0634, 0.0634, 0.0634, 0.1094, 0.1261, 0.1252, 0.0634, 0.0672, 0.0634,\n         0.2549],\n        [0.0987, 0.0798, 0.0798, 0.0798, 0.0798, 0.1362, 0.0798, 0.1077, 0.0798,\n         0.1785],\n        [0.0685, 0.0685, 0.0685, 0.0685, 0.0685, 0.1385, 0.0685, 0.0685, 0.0685,\n         0.3131],\n        [0.1161, 0.0867, 0.0867, 0.1087, 0.0867, 0.1672, 0.0867, 0.0867, 0.0877,\n         0.0867],\n        [0.0769, 0.0906, 0.0769, 0.0769, 0.0769, 0.1138, 0.1039, 0.1129, 0.1398,\n         0.1314],\n        [0.0887, 0.1889, 0.0887, 0.0887, 0.0887, 0.1016, 0.0887, 0.0887, 0.0887,\n         0.0887],\n        [0.0939, 0.0939, 0.0939, 0.1547, 0.0939, 0.0939, 0.0939, 0.0939, 0.0939,\n         0.0939],\n        [0.1183, 0.1342, 0.0845, 0.1103, 0.0837, 0.1227, 0.0909, 0.0837, 0.0837,\n         0.0881],\n        [0.0804, 0.2258, 0.0557, 0.2746, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557,\n         0.0851],\n        [0.0596, 0.1807, 0.0596, 0.0596, 0.0596, 0.1752, 0.0596, 0.1520, 0.0596,\n         0.1348],\n        [0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882, 0.0882,\n         0.2059]], grad_fn=<SoftmaxBackward>)\ntorch.return_types.max(\nvalues=tensor([0.2756, 0.1687, 0.2170, 0.3164, 0.1990, 0.1578, 0.3677, 0.1243, 0.2058,\n        0.2758, 0.2218, 0.2862, 0.1696, 0.1836, 0.2066, 0.2208, 0.1402, 0.1795,\n        0.1551, 0.1330, 0.3647, 0.2549, 0.1785, 0.3131, 0.1672, 0.1398, 0.1889,\n        0.1547, 0.1342, 0.2746, 0.1807, 0.2059]),\nindices=tensor([5, 3, 1, 1, 2, 5, 6, 3, 3, 9, 9, 6, 6, 3, 9, 3, 4, 6, 5, 9, 1, 9, 9, 9,\n        5, 8, 1, 3, 1, 3, 1, 9]))\ntorch.return_types.max(\nvalues=tensor([0.2756, 0.1687, 0.2170, 0.3164, 0.1990, 0.1578, 0.3677, 0.1243, 0.2058,\n        0.2758, 0.2218, 0.2862, 0.1696, 0.1836, 0.2066, 0.2208, 0.1402, 0.1795,\n        0.1551, 0.1330, 0.3647, 0.2549, 0.1785, 0.3131, 0.1672, 0.1398, 0.1889,\n        0.1547, 0.1342, 0.2746, 0.1807, 0.2059]),\nindices=tensor([5, 3, 1, 1, 2, 5, 6, 3, 3, 9, 9, 6, 6, 3, 9, 3, 4, 6, 5, 9, 1, 9, 9, 9,\n        5, 8, 1, 3, 1, 3, 1, 9]))\ntensor([5, 3, 1, 1, 2, 5, 6, 3, 3, 9, 9, 6, 6, 3, 9, 3, 4, 6, 5, 9, 1, 9, 9, 9,\n        5, 8, 1, 3, 1, 3, 1, 9])\ntensor([4, 4, 4, 1, 1, 0, 0, 8, 8, 7, 6, 5, 2, 8, 6, 3, 4, 9, 5, 4, 7, 6, 8, 8,\n        1, 9, 8, 5, 6, 7, 9, 7])\ntensor([False, False, False,  True, False, False, False, False, False, False,\n        False, False, False, False, False,  True,  True, False,  True, False,\n        False, False, False, False, False, False, False, False, False, False,\n        False, False])\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\ntensor(4)\n"
    }
   ],
   "source": [
    "if required_training:\n",
    "    model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">12. Plot Loss</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_loss, color='r', label=\"train loss\")\n",
    "plt.plot(x, epoch_test_loss, color='b', label=\"validation loss\")\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">13. Plot Accuracy</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_acc, color='r', label=\"train accuracy\")\n",
    "plt.plot(x, epoch_test_acc, color='b', label=\"validation accuracy\")\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='center right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">14. Loading the Model </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "cnn_model = MyModel()\n",
    "\n",
    "models = 'models'\n",
    "\n",
    "model_file_name = 'cifar10_cnn_model.pt'\n",
    "\n",
    "model_path = os.path.join(models, model_file_name)\n",
    "\n",
    "# loading the model and getting model parameters by using load_state_dict\n",
    "cnn_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">15. Model Prediction</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, train_config, batch_input):\n",
    "    \n",
    "    # send model to cpu/cuda according to your system configuration\n",
    "    model.to(train_config.device)\n",
    "    \n",
    "    # it is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "\n",
    "    data = batch_input.to(train_config.device)\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    # Score to probability using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "\n",
    "    # get the max probability\n",
    "    pred_prob = prob.data.max(dim=1)[0]\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">16. Perform Inference on sample images </font>\n",
    "\n",
    "For prediction, we need to transform the data in the same way as we have done during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "batch_size = 5\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    train_config.device = \"cuda\"\n",
    "else:\n",
    "    train_config.device = \"cpu\"\n",
    "    \n",
    "    \n",
    "\n",
    "# load test data without image transformation\n",
    "test = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root=train_config.data_root, train=False, download=False, \n",
    "                   transform=transforms.functional.to_tensor),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    "    )\n",
    "\n",
    "try:\n",
    "    mean, std = get_mean_std_train_data(data_root)\n",
    "    assert len(mean) == len(std) == 3\n",
    "except:\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "\n",
    "# load testdata with image transformation\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "test_trans = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root=train_config.data_root, train=False, download=False, transform=image_transforms),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    "    )\n",
    "\n",
    "for data, _ in test_trans:\n",
    "    # pass the loaded model\n",
    "    pred, prob = prediction(cnn_model, train_config, data)\n",
    "    break\n",
    "    \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (3, 3)\n",
    "for images, label in test:\n",
    "    for i, img in enumerate(images):\n",
    "        img = transforms.functional.to_pil_image(img)\n",
    "        plt.imshow(img)\n",
    "        plt.gca().set_title('Pred: {0}({1:0.2}), Label: {2}'.format(classes[pred[i]], prob[i], classes[label[i]]))\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">17. Report your findings</font>\n",
    "- Given an inferior model, tuning epoch or learning rate or batch size will not improve accuracy too much to meet 75% target \n",
    "- Use Dropout layer does improve my model by a large margin\n",
    "- all else being euqal,  smaller learning rate does not produce better accuracy.  e.g. learning rate 0.001 performs poorly than 0.01\n",
    "- 75% is not easy to achieve without adding more conv2d layers and more conv2d filters\n",
    "- conv2d with padding seems to do better than without padding\n",
    "- I do not quite understand yet about the plot. why traing loss and accuracy is worse than validation loss and accurancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# <font style=\"color:blue\">References</font>\n",
    "\n",
    "1. https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "1. https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('torch': conda)",
   "language": "python",
   "name": "python37564bittorchcondadcfb9d866495402cbc9e7774e81a38cc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}